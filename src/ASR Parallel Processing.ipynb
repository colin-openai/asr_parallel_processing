{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9c88e9b",
   "metadata": {},
   "source": [
    "# ASR Parallel Processing\n",
    "\n",
    "This notebook contains the results of the experiment documented in [here](https://docs.google.com/document/d/16ifixrlyDK5A6-MmYMm8HEdJPwtyCmiUTc8HdWlJxM4/edit).\n",
    "\n",
    "The outcome of this test should give us guidance for customers on whether they can process long audio files split in parallel, and whether this affects results drastically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d9caa203",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import openai\n",
    "import time\n",
    "from pydub import AudioSegment\n",
    "from pydub.utils import make_chunks\n",
    "import requests\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from math import ceil\n",
    "# Transcription compare comes from this repo: https://github.com/voicegain/transcription-compare\n",
    "# Clone it and install to your virtual environment with `python setup.py transcription_compare`\n",
    "from transcription_compare.levenshtein_distance_calculator import UKKLevenshteinDistanceCalculator\n",
    "from transcription_compare.tokenizer import CharacterTokenizer, WordTokenizer\n",
    "from transcription_compare.local_optimizer.digit_util import DigitUtil\n",
    "from transcription_compare.local_optimizer.local_cer_optimizer import LocalCerOptimizer\n",
    "from transcription_compare.results import MultiResult\n",
    "\n",
    "from asr import call_asr\n",
    "from transformers import convert_mp4_to_mp3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "38f8b2d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gregbrockman_futureofllms.mp3', 'gregbrockman_futureofllms.mp4']\n"
     ]
    }
   ],
   "source": [
    "# set API key\n",
    "openai.api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Set data directory\n",
    "data_dir = os.path.join(os.pardir,'data','long_video')\n",
    "\n",
    "# Get references for audio files\n",
    "audio_files = sorted([x for x in os.listdir(data_dir) ])\n",
    "print(audio_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a8aa11f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcription_extractor(audio_filepath):\n",
    "    response = call_asr(openai.api_key,audio_filepath)\n",
    "    return(response)\n",
    "\n",
    "def make_chunks_updated(audio_segment, chunk_length):\n",
    "    \"\"\"\n",
    "    Breaks an AudioSegment into chunks that are <chunk_length> milliseconds\n",
    "    long.\n",
    "    if chunk_length is 50 then you'll get a list of 50 millisecond long audio\n",
    "    segments back (except the last one, which can be shorter)\n",
    "    \"\"\"\n",
    "    number_of_chunks = ceil(len(audio_segment) / float(chunk_length))\n",
    "    return [audio_segment[i * chunk_length:(i + 1) * chunk_length]\n",
    "            for i in range(int(number_of_chunks))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "12f46e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing file from location by giving its path\n",
    "full_audio_file = AudioSegment.from_mp3(os.path.join(data_dir,audio_files[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47e2ed4",
   "metadata": {},
   "source": [
    "## Transcription\n",
    "\n",
    "We will perform two transcriptions to get our sets to run through the API and compare\n",
    "- First we'll take the full file, run it into the ASR API and save the responses along with the elapsed time\n",
    "- Next we'll take the file, break it into 5 minute chunks and do the same\n",
    "- Lastly we'll take the file, break it into 10 minute chunks and pull responses and times"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c86e8b",
   "metadata": {},
   "source": [
    "### Long File Transcription\n",
    "\n",
    "This section transcribes the full file with no splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "aa3de0ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start time is Thu Dec 15 09:59:28 2022\n",
      "Sending request\n",
      "Request successful\n",
      "End time is Thu Dec 15 10:02:02 2022\n",
      "Execution time: 154.58868384361267 seconds\n"
     ]
    }
   ],
   "source": [
    "full_st = time.time()\n",
    "print(f'Start time is {time.ctime()}')\n",
    "full_response = call_asr(openai.api_key,os.path.join(data_dir,audio_files[0]))\n",
    "full_et = time.time()\n",
    "print(f'End time is {time.ctime()}')\n",
    "\n",
    "full_elapsed_time = full_et - full_st\n",
    "print('Execution time:', full_elapsed_time, 'seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c263cc8",
   "metadata": {},
   "source": [
    "### 5 Minute Chunk Transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1339a24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set 5 minute chunks directory\n",
    "chunks_5_dir = os.path.join(os.curdir,'chunks_5')\n",
    "\n",
    "# create the directory if it doesn't yet exist\n",
    "if not os.path.isdir(chunks_5_dir):\n",
    "    os.mkdir(chunks_5_dir)\n",
    "    \n",
    "# clear any existing files down\n",
    "if len(os.listdir(chunks_5_dir)) > 0:\n",
    "    os.system(f\"rm {chunks_5_dir}/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4b72fc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks_5 = make_chunks_updated(full_audio_file, 300000)\n",
    "\n",
    "l = len(chunks_5)\n",
    "for i, ch in enumerate(chunks_5):\n",
    "\n",
    "    ch.export(os.path.join(chunks_5_dir,'chunk_5_' + str(i) + '.mp3'), format='mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6783d87b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./chunks_5/chunk_5_0.mp3',\n",
       " './chunks_5/chunk_5_1.mp3',\n",
       " './chunks_5/chunk_5_2.mp3',\n",
       " './chunks_5/chunk_5_3.mp3',\n",
       " './chunks_5/chunk_5_4.mp3',\n",
       " './chunks_5/chunk_5_5.mp3',\n",
       " './chunks_5/chunk_5_6.mp3',\n",
       " './chunks_5/chunk_5_7.mp3',\n",
       " './chunks_5/chunk_5_8.mp3',\n",
       " './chunks_5/chunk_5_9.mp3']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks_5_files = [os.path.join(os.curdir,'chunks_5',x) for x in sorted(os.listdir(chunks_5_dir))]\n",
    "chunks_5_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "60708022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending request\n",
      "Sending request\n",
      "Sending request\n",
      "Sending request\n",
      "Sending request\n",
      "Sending request\n",
      "Sending request\n",
      "Sending request\n",
      "Sending request\n",
      "Sending request\n",
      "Request successful\n",
      "Request successful\n",
      "Request successful\n",
      "Request successful\n",
      "Request successful\n",
      "Request successful\n",
      "Request successful\n",
      "Request successful\n",
      "Request successful\n",
      "Request successful\n",
      "\n",
      " time elapsed is : 111.0569999217987\n"
     ]
    }
   ],
   "source": [
    "with ThreadPoolExecutor(max_workers=10) as pool:\n",
    "    start_5_ts =time.time()\n",
    "    response_list_5 = list(pool.map(transcription_extractor,chunks_5_files))\n",
    "    end_5_ts =time.time()\n",
    "    elapsed_5 = (end_5_ts - start_5_ts)  \n",
    "    print(\"\\n\",\"time elapsed is :\", elapsed_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75df0912",
   "metadata": {},
   "source": [
    "### 10 Minute Chunk Transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "db9940d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set 10 minute chunks directory\n",
    "chunks_10_dir = os.path.join(os.curdir,'chunks_10')\n",
    "\n",
    "# create the directory if it doesn't yet exist\n",
    "if not os.path.isdir(chunks_10_dir):\n",
    "    os.mkdir(chunks_10_dir)\n",
    "    \n",
    "# clear any existing files down\n",
    "if len(os.listdir(chunks_10_dir)) > 0:\n",
    "    os.system(f\"rm {chunks_10_dir}/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "741b52a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks_10 = make_chunks_updated(full_audio_file, 600000)\n",
    "\n",
    "l = len(chunks_10)\n",
    "for i, ch in enumerate(chunks_10):\n",
    "\n",
    "    ch.export(os.path.join(chunks_10_dir,'chunk_10_' + str(i) + '.mp3'), format='mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "495536fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./chunks_10/chunk_10_0.mp3',\n",
       " './chunks_10/chunk_10_1.mp3',\n",
       " './chunks_10/chunk_10_2.mp3',\n",
       " './chunks_10/chunk_10_3.mp3',\n",
       " './chunks_10/chunk_10_4.mp3']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks_10_files = [os.path.join(os.curdir,'chunks_10',x) for x in sorted(os.listdir(chunks_10_dir))]\n",
    "chunks_10_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e0a70459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending requestSending request\n",
      "Sending request\n",
      "Sending request\n",
      "\n",
      "Sending request\n",
      "Request successful\n",
      "Request successful\n",
      "Request successful\n",
      "Request successful\n",
      "Request successful\n",
      "\n",
      " time elapsed is : 117.20787191390991\n"
     ]
    }
   ],
   "source": [
    "with ThreadPoolExecutor(max_workers=10) as pool:\n",
    "    start_10_ts =time.time()\n",
    "    response_list_10 = list(pool.map(transcription_extractor,chunks_10_files))\n",
    "    end_10_ts =time.time()\n",
    "    elapsed_10 = (end_10_ts - start_10_ts)  \n",
    "    print(\"\\n\",\"time elapsed is :\", elapsed_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1904ef3c",
   "metadata": {},
   "source": [
    "### Timing Summary\n",
    "\n",
    "Customer quoted 48 minutes for 48 minute file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a38b0fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "improvement_5 = round(full_elapsed_time/elapsed_5-1,2)\n",
    "improvement_10 = round(full_elapsed_time/elapsed_10-1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8c4bafc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing one file took 0:02:34.588684\n",
      "Processing ten minute chunks took 0:01:57.207872 and delivered a 32.0% improvement\n",
      "Processing five minute chunks took 0:01:51.057000 and delivered a 39.0% improvement\n"
     ]
    }
   ],
   "source": [
    "from datetime import timedelta\n",
    "\n",
    "print(f\"Processing one file took {str(timedelta(seconds=full_elapsed_time))}\")\n",
    "print(f\"Processing ten minute chunks took {str(timedelta(seconds=elapsed_10))} and delivered a {improvement_10*100}% improvement\")\n",
    "print(f\"Processing five minute chunks took {str(timedelta(seconds=elapsed_5))} and delivered a {improvement_5*100}% improvement\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9247c201",
   "metadata": {},
   "source": [
    "## Accuracy\n",
    "\n",
    "Now we'll compare the outputs to confirm whether the chunking decreases accuracy meaningfully\n",
    "\n",
    "TODO: This is not completed, as the results above were so positive we have not investigated the chunking method further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7e0e6ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks_5_list = []\n",
    "for response in response_list_5:\n",
    "    chunks_5_list.append(response.json()['text'])\n",
    "    \n",
    "chunks_10_list = []\n",
    "for response in response_list_10:\n",
    "    chunks_10_list.append(response.json()['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6626d2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_text = full_response.json()['text']\n",
    "chunks_10_text = ''.join(chunks_10_list)\n",
    "chunks_5_text = ''.join(chunks_5_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1968f637",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50549, 50416, 50443)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(full_text), len(chunks_10_text), len(chunks_5_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8966ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculator = UKKLevenshteinDistanceCalculator(\n",
    "        tokenizer=WordTokenizer(),\n",
    "        get_alignment_result=True,\n",
    "        local_optimizers=[DigitUtil(process_output_digit=True), LocalCerOptimizer()]\n",
    "    )\n",
    "\n",
    "output_results = calculator.get_distance(reference_text, value,\n",
    "                                          brackets_list=[\"[]\", \"()\", \"<>\"],\n",
    "                                          to_lower=True,\n",
    "                                          remove_punctuation=True,\n",
    "                                          use_alternative_spelling=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15b5b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_transcription_compare(reference_data, comparison_file, output_html_path):\n",
    "    print(\"Start to compare results\")\n",
    "\n",
    "    #with open(reference_path, \"r\", encoding='utf-8') as reference_file:\n",
    "        #reference_text = reference_file.read()\n",
    "\n",
    "    calculator = UKKLevenshteinDistanceCalculator(\n",
    "        tokenizer=WordTokenizer(),\n",
    "        get_alignment_result=True,\n",
    "        local_optimizers=[DigitUtil(process_output_digit=True), LocalCerOptimizer()]\n",
    "    )\n",
    "\n",
    "    output_all = dict()  # (output identifier -> output string)\n",
    "    for output_path in output_file_list:\n",
    "        with open(output_path, \"r\", encoding='utf-8') as output_file:\n",
    "            output_text = output_file.read()\n",
    "        output_path_name = os.path.basename(output_path)\n",
    "        output_all[output_path_name] = output_text\n",
    "    #logging.info(\"Finish reading all results\")\n",
    "\n",
    "    output_results = dict()  # (output_identifier -> output_string)\n",
    "    for (key, value) in output_all.items():\n",
    "        logging.info(\"Start to process {}\".format(key))\n",
    "        output_results[key] = calculator.get_distance(reference_text, value,\n",
    "                                                      brackets_list=[\"[]\", \"()\", \"<>\"],\n",
    "                                                      to_lower=True,\n",
    "                                                      remove_punctuation=True,\n",
    "                                                      use_alternative_spelling=True)\n",
    "\n",
    "    #logging.info(\"Merge all results into one HTML\")\n",
    "    calculator_local = UKKLevenshteinDistanceCalculator(\n",
    "                tokenizer=CharacterTokenizer(),\n",
    "                get_alignment_result=False)\n",
    "\n",
    "    result = MultiResult(output_results, calculator_local)\n",
    "    s = result.to_html()\n",
    "\n",
    "    with open(output_html_path, 'w') as f:\n",
    "        f.write(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1877d1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculator = UKKLevenshteinDistanceCalculator(\n",
    "        tokenizer=WordTokenizer(),\n",
    "        get_alignment_result=True,\n",
    "        local_optimizers=[DigitUtil(process_output_digit=True), LocalCerOptimizer()]\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
